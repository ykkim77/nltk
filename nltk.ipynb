{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fcsiz19E9Zd"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9StC8xIybkS"
      },
      "source": [
        "## Corpus\r\n",
        "\r\n",
        "1. isolate corpus: gutenberg, webtext\r\n",
        "1. cattegorized corpu: brown\r\n",
        "1. overlapping corpus\r\n",
        "1. Temportal corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGItWTZFfcp"
      },
      "source": [
        "from nltk.corpus import brown as cb\r\n",
        "from nltk.corpus import gutenberg as gb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzEbFH1vJVFs"
      },
      "source": [
        "nltk.download('brown')       #nltl brwon corpus 다운 받기\r\n",
        "nltk.download('gutenberg')   #nltl gutenberg corpus 다운 받기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hvK9dVBJbJL"
      },
      "source": [
        "cb.fileids()                  # brown corpus가 여러가지 파일 형태로 구성되 있다는 것을 확인해볼 수 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph5JSRQMKLwz"
      },
      "source": [
        "gb.fileids()             # gutenberg corpus가 여러가지 파일 형태로 구성되 있다는 것을 확인해볼 수 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pcTLlvWKcpJ"
      },
      "source": [
        "cb.categories()    #Brown corpus는 카테고리화 corpus이기 때문에 카테고리 정보를 가지고 있다는 것을 확인할 수 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_en_6zxKnSE"
      },
      "source": [
        "# brown corpus의 총 단어 개수는 얼마나 되는지 알아보기\r\n",
        "brown_words = cb.words()     \r\n",
        "print('brown corpus의 총 단어 개수' ,len(brown_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTp8sU13LmS"
      },
      "source": [
        "#특정 fileids 에 있는 단어 출력\r\n",
        "\r\n",
        "cb.words(fileids='ca01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkbGLucj2kT_"
      },
      "source": [
        "# gutenberg corpus의 총 단어 개수는 얼마나 되는지 알아보기\r\n",
        "guten_words = gb.words()     \r\n",
        "print('brown corpus의 총 단어 개수' ,len(guten_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee6WvA7pLYHt"
      },
      "source": [
        "#brown corpus categrial 별로 단어를 확인해보기\r\n",
        "cb.words(categories = 'adventure')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfBRLGS2MJdv"
      },
      "source": [
        "#gutenburg 의 특정 fileid 에서 단어 가지고 오기\r\n",
        "\r\n",
        "gb.words(fileids='austen-emma.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHK8PjucNC4O"
      },
      "source": [
        "# brown의 특정 파일의 텍스트 전체를 가져오기\r\n",
        "\r\n",
        "raw_text=cb.raw(fileids= 'ca01')\r\n",
        "print(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AGVpBFT4Skf"
      },
      "source": [
        "# gutenberg의 특정 파일의 텍스트 전체를 가져오기\r\n",
        "\r\n",
        "raw_text=gb.raw(fileids= 'austen-emma.txt')\r\n",
        "print(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f_-aLEGOPwR"
      },
      "source": [
        "**## nltk tokennizing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjdG7aNW43X5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5vzfiQgQU7A"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsmgXttuOTmG"
      },
      "source": [
        "#sentence tokenizing\r\n",
        "# 문단 => 문장\r\n",
        "\r\n",
        "from nltk.tokenize import sent_tokenize\r\n",
        "\r\n",
        "raw_text = gb.raw(fileids= 'austen-emma.txt')\r\n",
        "gb.words(fileids='austen-emma.txt')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uAiW6g4QEzi"
      },
      "source": [
        "sent_tokenize(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7eFrkfQtkR"
      },
      "source": [
        "sentence = sent_tokenize(raw_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgOKKLoFQ49q"
      },
      "source": [
        "#word tokenizing\r\n",
        "#sentence => words\r\n",
        "\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "\r\n",
        "word_tokenize(sentence[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCNZ3TEjRtLN"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\r\n",
        "\r\n",
        "wpt = WordPunctTokenizer()\r\n",
        "wpt.tokenize(sentence[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKIZK7rtSYK0"
      },
      "source": [
        "## NLTK stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of6sn-VYTNb8"
      },
      "source": [
        "tokens = word_tokenize(sentence[0])\r\n",
        "\r\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYLvn34HST9x"
      },
      "source": [
        "from nltk.stem import PorterStemmer\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "ps = PorterStemmer()\r\n",
        "ps.stem(tokens[1])\r\n",
        "stem_tokens = []\r\n",
        "for token in tokens:\r\n",
        "  stem_token = ps.stem(token)\r\n",
        "  stem_tokens.append(stem_token)\r\n",
        "\r\n",
        "stem_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9uc89K6WZyL"
      },
      "source": [
        "# Stemming을 통해 단어가 바뀐것만 추출해서 확인\r\n",
        "\r\n",
        "mask = [token==stem_token for token, stem_token in zip(tokens, stem_tokens)]\r\n",
        "masked_tokens = np.array(tokens)[mask]\r\n",
        "masked_stem_tokens = np.array(stem_tokens)[mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4asOUcfOXiq-"
      },
      "source": [
        "np.stack([masked_tokens,masked_stem_tokens],-1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}